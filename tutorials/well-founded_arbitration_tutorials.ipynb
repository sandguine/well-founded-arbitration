{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1417bd0c-7d01-48cb-8905-a4ee0de4f4e0",
   "metadata": {},
   "source": [
    "### Vector and Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cf47f-4e95-47c3-8877-37313fbb6436",
   "metadata": {},
   "source": [
    "Let's start with $K$ = 2 experts, and $|A|$ = 2 actions, Expert 1 = [0.9, 0.1], Expert 2 = [0.7, 0.3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91576bfa-7b33-4e46-9e8a-6e968d118da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K, A = 2, 2\n",
    "E1 = [0.9, 0.1]\n",
    "E2 = [0.7, 0.3]\n",
    "Q = [E1, E2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1124e66-fe63-4994-aa57-f0f5ed4f8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9, 0.1], [0.7, 0.3]]\n"
     ]
    }
   ],
   "source": [
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6fa15-ef90-4823-87d3-38ebb80da54a",
   "metadata": {},
   "source": [
    "##### What are the dimensions of the full data structure that stores both experts‚Äô predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bcced9-4888-4cc5-b048-8b01c03c9002",
   "metadata": {},
   "source": [
    "Since we have 2 experts and 2 actions, the dimension is a matrix of 2 by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6f95c-3583-470d-a019-6ab126d12671",
   "metadata": {},
   "source": [
    "##### How would we write the element that stores Expert‚ÄØ2‚Äôs score for Action‚ÄØ1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ab5e7-2f49-42d8-ab14-ac63670a8371",
   "metadata": {},
   "source": [
    "$E_2A_1 = Q[1, 0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f955ae-c373-4279-ae8b-b0ed37079dce",
   "metadata": {},
   "source": [
    "##### Why should we use as a $ùêæ \\times ‚à£ùê¥‚à£$ matrix instead of a flat list?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c396fb1-ce08-4e2a-ad5d-7c0a0a3da5bb",
   "metadata": {},
   "source": [
    "Because we can use aggregation and take advantage of linear algebra such that when we apply softmax it can be on either dimension, per row, per column, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e29dc56-6dfe-46ef-bbc8-fb814f673c9e",
   "metadata": {},
   "source": [
    "### Log-Sum-Exp and Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f49894-fb22-46a1-af17-d97140956a7b",
   "metadata": {},
   "source": [
    "##### Why shouldn't we use raw score as probabilities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b004d2-b303-4c0c-b852-63d8cdbd3fb2",
   "metadata": {},
   "source": [
    "This is because the raw score themselves are not a probability distribution since they are summing to 1 and can't be less than 0. Also, if we use raw score directly, we can't express the uncertainty between the option and this is where applying softmax over it we can convert the score into probability distribution instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195be5a3-ca5d-4edc-b3df-d9a7ac42ef9c",
   "metadata": {},
   "source": [
    "##### Let's write a general softmax the softmax of a score vector $s = [s_1, s_2]$ with temperature $\\tau$. What does lowering $\\tau$ do to the resulting probabilities?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa7f442-8dcf-4643-9905-5a84f8e6ce15",
   "metadata": {},
   "source": [
    "To answer this question well, we have to first look at the equation of softmax function but started with this particular setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea859eb-d904-4cb1-a45b-126073c1f43b",
   "metadata": {},
   "source": [
    "From Wikipedia: the softmax function takes as input a tuple z of K real numbers, and normalizes it into a probability distribution consisting of K probabilities proportional to the exponentials of the input numbers. That is, prior to applying softmax, some tuple components could be negative, or greater than one; and might not sum to 1; but after applying softmax, each component will be in the interval $(0,1)$, and the components will add up to 1, so that they can be interpreted as probabilities. Furthermore, the larger input components will correspond to larger probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b99ea6-79ae-4674-be12-7fc55e9f0446",
   "metadata": {},
   "source": [
    "Formally, the standard (unit) softmax function $\\sigma: \\mathbb{R}^K \\rightarrow (0, 1)^K$, where $K > 1$, takes a tuple $z = (z_1, ..., z_K) \\in \\mathbb(R)^K$ and computes each components of vector $\\sigma(z) \\in (0,1)^K$ with: $$ \\sigma(z)_i = \\frac{e^{z_i}}{\\Sigma_{j=1}^{K}{e^{z_j}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4f961-f66b-48dc-b741-b80f1803eedd",
   "metadata": {},
   "source": [
    "So this is the standard softmax equation, what that means in words is that we apply exponential function over each individual element of $z$ then divided them by the sum of all of the exponentials. The normalization is to ensure that the sum of the components of the output vector $\\sigma(z)$ is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7217c2-f10b-43f8-9dc6-2dbab20ad8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30712d24-1f35-4ca7-9399-7dc292a4926f",
   "metadata": {},
   "source": [
    "##### Using $\\tau = 1$, hand‚Äëcalculate softmax([0,0]). What should the distribution look like, and why?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfdfb8e-5a01-4b4d-8a49-c6fa7f74b3da",
   "metadata": {},
   "source": [
    "### KL-divergence for Measuring Policy Disagreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace05e6-810a-4c4b-aaf9-a24d4cdffaa7",
   "metadata": {},
   "source": [
    "Assume two softmax policies $\\pi_1 = [0.8, 0.2], \\pi_2 = [0.6, 0.4].$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c26a0-7eb2-4eda-8072-0168cf15b0b0",
   "metadata": {},
   "source": [
    "##### Is $KL(\\pi_1 || \\pi_2)$ equivalence to $KL(\\pi_2 || \\pi_1)$? What's the intuition behind this and explain in words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011ad77-b5d9-4f34-a4d6-6c9117937aee",
   "metadata": {},
   "source": [
    "##### Under what exact condition is $KL$ divergence equal to‚ÄØ0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa7c28-7c5a-4a61-bb14-ed51e3539b49",
   "metadata": {},
   "source": [
    "##### Suppose $KL(\\pi_1 || \\pi_2)$, what does ‚Äú0.02 nats‚Äù this mean intuitively?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313cecb-0847-4c1d-9eb1-a6b603cacb6c",
   "metadata": {},
   "source": [
    "### Mutual Information for \"Keeping only Useful Bits\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8534a8-6f9b-4451-add1-971f7d1c2694",
   "metadata": {},
   "source": [
    "Let's say we have a random variable $Q$ expert scores, and abstraction of $\\varphi(Q)$ (compressed abstract)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ea2d580-5588-4b3d-acb4-538fcfc10b5b",
   "metadata": {},
   "source": [
    "##### Express mutual information with entropy $I(Q, \\varphi(Q))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1779e-0781-4513-a65c-12e40795d444",
   "metadata": {},
   "source": [
    "##### What does $I(Q;œï(Q))=0$ tell about $\\varphi(Q)$? What if $I(Q;\\varphi(Q))=H(Q)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3d507-7c02-4574-a611-e9201c05df8f",
   "metadata": {},
   "source": [
    "##### Why might we want to minimize $I(Q;\\varphi(Q))$ while still respecting decision quality? (Hint: ‚Äúcompression without losing the action boundary.‚Äù)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bb1b5-ff4f-4e42-a291-cf08c06775b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
